{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on Cross Lingual Transfer for Intent Detection\n",
    "### Zero Shot Experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to prepare the data from Schuster et al. For now we are only examining English and Spanish datasets, since preprocessing Thai requires extra steps and is slightly more complex(tokenization). Firstly, we parse the tsv data into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "import pickle\n",
    "import sklearn\n",
    "import torch\n",
    "import numpy as np\n",
    "#from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening /home/santi/BA/multilingual_task_oriented_dialog_slotfilling/en/train-en.tsv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'training_files/en_train.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-611962904355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# eng train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0men_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/santi/BA/multilingual_task_oriented_dialog_slotfilling/en/train-en.tsv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0men_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_files/en_train.p\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# eng eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression, protocol)\u001b[0m\n\u001b[1;32m   2671\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2673\u001b[0;31m         \u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m     def to_clipboard(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training_files/en_train.p'"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "with open('label_map.json','r') as f:\n",
    "    mapping = json.load(f)\n",
    "    mapping = {int(k):v for k,v in mapping.items()}\n",
    "    \n",
    "    \n",
    "# preprocess training and test files to pandas df\n",
    "\n",
    "# eng train\n",
    "en_df, en_mapping = df_format((\"/home/santi/BA/multilingual_task_oriented_dialog_slotfilling/en/train-en.tsv\"),mapping)\n",
    "en_df.to_pickle(\"training_files/en_train.p\")\n",
    "\n",
    "# eng eval\n",
    "en_df_eval, en_mapping = df_format(\"/home/santi/BA/multilingual_task_oriented_dialog_slotfilling/en/eval-en.tsv\",mapping)\n",
    "en_df_eval.to_pickle(\"training_files/en_eval.p\")\n",
    "\n",
    "# eng test\n",
    "en_df_test, en_mapping = df_format(\"/home/santi/BA/multilingual_task_oriented_dialog_slotfilling/en/test-en.tsv\",mapping)\n",
    "en_df_test.to_pickle(\"training_files/en_test.p\")\n",
    "\n",
    "# es train\n",
    "es_df, es_mapping = df_format(\"/home/santi/BA/multilingual_task_oriented_dialog_slotfilling/es/train-es.tsv\",mapping)\n",
    "es_df.to_pickle(\"training_files/es_train.p\")\n",
    "\n",
    "# es eval\n",
    "es_df_eval, es_mapping = df_format(\"/home/santi/BA/multilingual_task_oriented_dialog_slotfilling/es/eval-es.tsv\",mapping)\n",
    "es_df_eval.to_pickle(\"training_files/es_eval.p\")\n",
    "\n",
    "# es test\n",
    "es_df_test, es_mapping = df_format(\"/home/santi/BA/multilingual_task_oriented_dialog_slotfilling/es/test-es.tsv\",mapping)\n",
    "es_df_test.to_pickle(\"training_files/es_test.p\")\n",
    "\n",
    "\n",
    "# th train\n",
    "th_df, th_mapping = df_format(\"/home/santi/BA/multilingual_task_oriented_dialog_slotfilling/th/train-th_TH.tsv\",mapping)\n",
    "th_df.to_pickle(\"training_files/th_train.p\")\n",
    "\n",
    "# th eval\n",
    "th_df_eval, th_mapping = df_format(\"/home/santi/BA/multilingual_task_oriented_dialog_slotfilling/th/eval-th_TH.tsv\",mapping)\n",
    "th_df_eval.to_pickle(\"training_files/th_eval.p\")\n",
    "\n",
    "# th test\n",
    "th_df_test, th_mapping = df_format(\"/home/santi/BA/multilingual_task_oriented_dialog_slotfilling/th/test-th_TH.tsv\",mapping)\n",
    "th_df_test.to_pickle(\"training_files/th_test.p\")\n",
    "\n",
    "mapping_list = list(mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train = en_df.drop_duplicates(\"text\")\n",
    "en_eval = en_df_eval.drop_duplicates(\"text\")\n",
    "en_test = en_df_test.drop_duplicates(\"text\")\n",
    "\n",
    "es_train = es_df.drop_duplicates(\"text\")\n",
    "es_eval = es_df_eval.drop_duplicates(\"text\")\n",
    "es_test = es_df_test.drop_duplicates(\"text\")\n",
    "\n",
    "th_train = th_df.drop_duplicates(\"text\")\n",
    "th_eval = th_df_eval.drop_duplicates(\"text\")\n",
    "th_test = th_df_test.drop_duplicates(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_full_train = pd.concat([en_train,en_eval])\n",
    "es_full_train = pd.concat([es_train,es_eval])\n",
    "th_full_train = pd.concat([th_train, th_eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2model = \"/home/santi/BA/final_models/\"\n",
    "path2model_en = \"/home/santi/BA/final_models/en/\"\n",
    "path2model_es = \"/home/santi/BA/final_models/es/\"\n",
    "path2model_th = \"/home/santi/BA/final_models/th/\"\n",
    "path2model_x = \"/home/santi/BA/final_models/x/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_wrong(wrong_predictions,model):\n",
    "    wrongs = [(inp.text_a,inp.label) for inp in wrong_predictions]\n",
    "    wrong_preds, vecs = model.predict([t for t,l in wrongs])\n",
    "\n",
    "    dom_corr = 0\n",
    "    weak_dom = 0\n",
    "    rem_alarms = [\"reminder\",\"alarm\"]\n",
    "    results = []\n",
    "\n",
    "    for (text, lab_true), lab_pred in zip(wrongs,wrong_preds):\n",
    "\n",
    "        lab_pred = mapping[lab_pred]\n",
    "        lab_true = mapping[lab_true]\n",
    "        dom_pred = lab_pred.split(\"/\")[0]\n",
    "        dom_true = lab_true.split(\"/\")[0]\n",
    "\n",
    "        if dom_pred == dom_true:\n",
    "            dom_corr += 1\n",
    "\n",
    "        if (dom_pred in rem_alarms) and (dom_true in rem_alarms):\n",
    "            weak_dom += 1    \n",
    "\n",
    "        results.append((text,lab_pred, lab_true))\n",
    "\n",
    "        #print(text,\"\\t\" ,lab_pred,\"\\t\", lab_true,\"\\t\", dom_pred,\"\\t\", dom_true)\n",
    "\n",
    "    return results, dom_corr/len(wrongs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro = lambda x,y:  sklearn.metrics.f1_score(x,y, average= 'macro')\n",
    "micro = lambda x,y:  sklearn.metrics.f1_score(x,y, average= 'micro')\n",
    "report = lambda x,y:  sklearn.metrics.classification_report(x,y,digits = 5,labels = list(range(0,12)), target_names = mapping_list)\n",
    "report_dict = lambda x,y:  sklearn.metrics.classification_report(x,y,digits = 5,output_dict = True,labels = list(range(0,12)),target_names = mapping_list)\n",
    "accuracy = lambda x,y:  sklearn.metrics.accuracy_score(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_eval(df, model, ex_name = \"experiment 1\", verbose = True):\n",
    "    results, predictions_vs, wrongs = model.eval_model(df, macro=macro, micro=micro,accuracy=accuracy, report=report, report_dict = report_dict)\n",
    "    results[\"name\"] = ex_name\n",
    "    \n",
    "    false_preds,dom_acc = analyze_wrong(wrongs,model)\n",
    "    results[\"wrong_predictions\"] = false_preds\n",
    "    results[\"domain_of_wrongs\"] = dom_acc\n",
    "    results[\"domain_accuracy\"] = results[\"accuracy\"] + (1-results[\"accuracy\"])*dom_acc\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"results for experiment: \",ex_name)\n",
    "\n",
    "        print(results[\"report\"])\n",
    "        print(\"domain accuracy: \",results[\"domain_accuracy\"])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load up a pretrained XLM model with a Max Ent layer for classification. Arguments are left pretty vanilla except fp16 which is not relevant for the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\"fp16\": False,'learning_rate':1e-5, 'num_train_epochs': 5, 'reprocess_input_data': True, 'overwrite_output_dir': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_xlmr(args, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train english model\n",
    "# full train = train + eval\n",
    "\n",
    "model.train_model(en_full_train, output_dir = path2model_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test eng\n",
    "results = custom_eval(en_test, model, \"train_en_test_en\")\n",
    "experiment_results[results[\"name\"]] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test es\n",
    "results = custom_eval(es_test, model, \"train_en_test_es\")\n",
    "experiment_results[results[\"name\"]] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, predicted, real in experiment_results[\"train_en_test_es\"][\"wrong_predictions\"]:\n",
    "    print(text, \"\\t\", predicted, \"\\t\", real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test th\n",
    "results = custom_eval(th_test, model, \"train_en_test_th\")\n",
    "experiment_results[results[\"name\"]] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, predicted, real in experiment_results[\"train_en_test_th\"][\"wrong_predictions\"]:\n",
    "    print(text, \"\\t\", predicted, \"\\t\", real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_model(es_full_train, output_dir = path2model_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = custom_eval(en_test, model, \"train_en_es_test_en\")\n",
    "experiment_results[results[\"name\"]] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = custom_eval(es_test, model, \"train_en_es_test_es\")\n",
    "experiment_results[results[\"name\"]] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = custom_eval(th_test, model, \"train_en_es_test_th\")\n",
    "experiment_results[results[\"name\"]] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_model(th_full_train, output_dir = path2model_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = custom_eval(th_test, model, \"train_en_es_th_test_th\")\n",
    "experiment_results[results[\"name\"]] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, predicted, real in experiment_results[\"train_en_es_th_test_th\"][\"wrong_predictions\"]:\n",
    "    print(text, \"\\t\", predicted, \"\\t\", real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = custom_eval(es_test, model, \"train_en_es_th_test_es\")\n",
    "experiment_results[results[\"name\"]] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = custom_eval(en_test, model, \"train_en_es_th_test_en\")\n",
    "experiment_results[results[\"name\"]] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SANITY CHECK #####\n",
    "def unique_sents(test_df, train_df):\n",
    "    print(\"unique utterances in test data out of :\", len(test_df))\n",
    "    unique_sents = []\n",
    "    train_set = set(train_df[\"text\"])\n",
    "    for sent in test_df[\"text\"]:\n",
    "        if sent not in train_set:\n",
    "            unique_sents.append(sent)\n",
    "    print(len(unique_sents)/len(test_df)*100,\"% of the sentences are unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuanto tiempo queda en mi alarma actual ? \t alarm/show_alarms \t alarm/time_left_on_alarm \t alarm \t alarmunique_sents(en_test, en_eval)\n",
    "unique_sents(en_test,en_full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sents(es_test, es_eval)\n",
    "unique_sents(es_test,es_full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sents(th_test, th_eval)\n",
    "unique_sents(th_test,th_full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I AM SANE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sent = lambda sent: mapping[model.predict([sent])[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some random tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sent(\"what's the weather in Potsdam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sent(\"don't wake me up tomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_sent(\"ตั้ง เวลา พรุ่ง บ่าย พรุ่งนี้\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sent(\"que temperatura hay aqui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sent(\"no necesito que levantarme el sabado\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sent(\"sabado no necesito que levantarme\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sent(\"ไม่ ต้อง ปลุก ฉัน วัน เสาร์ นะ\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_sent(\"วัน เสาร์ ไม่ ต้อง ปลุก ฉัน นะ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sent(\"you don't have to wake me up on saturday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sent(\"saturday you don't have to wake me up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_full_train[en_full_train[\"text\"].str.contains(\"^on (saturday|sunday|monday|tuesday)\",case=False, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_sent(\"I don't have to wake up early on saturday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a weird sentence \n",
    "predict_sent(\"saturday you don't have to wake me up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sent(\"am Samstag musst du mich nicht aufwecken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sent(\"ich nicht muss aufstehen am Samstag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"el sabado no necesito el despertador\" \n",
    "# doesn't work\n",
    "# implicit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"cuanto falta hasta el alarma\"\n",
    "\"cuanto tiempo queda hasta que me levanto\"\n",
    "\"que temperatura hay aqui\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
